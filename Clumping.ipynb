{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0483b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3433633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73fda8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_removal_threshold     = 1\n",
    "vectorizer_removal_threshold = 2\n",
    "grouping_similarity          = .6\n",
    "filepath = 'recipes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddea7d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collected:\n",
      "    - 4107 unique words found.\n",
      "    - most common words: ['\\n', '-', '.', '1', ',']\n",
      "    - least common words: ['www', 'yet', 'zinfandel', 'zip', 'zipper']\n",
      "\n",
      "\n",
      "Corpus loaded:\n",
      "    - 5000 sentences.\n",
      "    - longest sentence: \n",
      "\n",
      "<START> whole wheat yeast bread \n",
      " \n",
      " ingredients : \n",
      " - 1 cup ( 2 2 5 ml ) scalded milk \n",
      " - 1 / 4 cup ( 6 0 ml ) lard \n",
      " - 4 tsp ( 2 0 ml ) . salt \n",
      " - 1 / 4 cup ( 6 0 ml ) honey \n",
      " - 1 cup ( 2 2 5 ml ) water , 1 1 0 - 1 1 5 degrees \n",
      " - 2 pkg . dry yeast \n",
      " - 2 tbsp ( 3 0 ml ) . brown sugar \n",
      " - 2 cups ( 4 7 5 ml ) whole wheat flour \n",
      " - 3 cups ( 7 0 0 ml ) or more white flour \n",
      " \n",
      " directions : \n",
      " - mix scalded milk , lard , salt & honey and let cool to lukewarm - about 8 5 degrees ( 3 0 c . ) . \n",
      " - mix water , yeast & brown sugar and let stand to dissolve for 2 - 3 minutes . \n",
      " - add yeast mixture to milk mixture . \n",
      " - add whole wheat flour and enough white flour to make dough . \n",
      " - mix well . \n",
      " - knead 5 - 1 0 minutes . \n",
      " - put in bowl to rise until double in size . \n",
      " - punch down and divide into two portions . \n",
      " - let rest 5 - 1 0 minutes and then shape into two loaves . \n",
      " - let rise in pans one hour or until double in bulk . \n",
      " - bake at 3 7 5 degrees ( 2 0 0 c . ) for 5 minutes and 3 5 0 degrees ( 1 7 5 c . ) for 3 0 - 3 5 minutes . \n",
      " - remove from pans and let cool thoroughly before wrapping <END>\n",
      ".    \n",
      "    - shortest sentence: \n",
      "\n",
      "<START> test \n",
      " \n",
      " ingredients : \n",
      " - 1 kg pork \n",
      " \n",
      " directions : \n",
      " - combine the first 3 ingredients <END>\n",
      "Vectorizer created:\n",
      "    - 4107 unique words;\n",
      "    - 3369 CRV words\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(\n",
    "    filepath          = f'corpora/{filepath}',\n",
    "    spell_correct     = 'corpora/spelling_dictionary',\n",
    "    lemmatize         = False,\n",
    "    removal_threshold = corpus_removal_threshold)\n",
    "\n",
    "vectorizer = corpus.create_vectorizer(removal_threshold = vectorizer_removal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a0c5d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n",
      "twentieth\n"
     ]
    }
   ],
   "source": [
    "# get matrix of similarities between all words\n",
    "\n",
    "twentieth = vectorizer.vsize // 20\n",
    "differences = np.zeros((vectorizer.vsize, vectorizer.vsize,))\n",
    "\n",
    "for i in range(vectorizer.vsize):\n",
    "    word_diffs = keras.ops.einsum('v,bv->bv', vectorizer.matrix[i], vectorizer.matrix)\n",
    "    word_diffs = keras.ops.sqrt(word_diffs)\n",
    "    word_diffs = keras.ops.sum(word_diffs, axis = -1)\n",
    "    word_diffs *= word_diffs\n",
    "    differences[i] = word_diffs.numpy()\n",
    "    \n",
    "    if (i % twentieth == 0):\n",
    "        print('twentieth')\n",
    "\n",
    "differences *= (1 - np.eye(differences.shape[0], differences.shape[1]))\n",
    "similar_words = np.asarray(differences >= grouping_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f6726b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1450\n"
     ]
    }
   ],
   "source": [
    "coords = np.array(similar_words.nonzero())\n",
    "print(len(coords[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "837a146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliques Found: 282; Longest Clique: 10\n"
     ]
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/dsa/maximal-clique-problem-recursive-solution/\n",
    "\n",
    "def bron_kerbosch(R, P, X, graph):\n",
    "    if not P and not X:\n",
    "        yield R\n",
    "    while P:\n",
    "        v = P.pop()\n",
    "        yield from bron_kerbosch(\n",
    "            R.union({v}),\n",
    "            P.intersection(graph[v]),\n",
    "            X.intersection(graph[v]),\n",
    "            graph\n",
    "        )\n",
    "        X.add(v)\n",
    "\n",
    "\n",
    "edges = [(int(coords[0,i])+1, int(coords[1,i])+1) for i in range(coords.shape[1])]\n",
    "n = len(corpus.vocab)  # Number of nodes\n",
    "\n",
    "# Create an adjacency list from the edges\n",
    "graph = {i: set() for i in range(1, n + 1)}\n",
    "for u, v in edges:\n",
    "    graph[u].add(v)\n",
    "    graph[v].add(u)\n",
    "# Graph [x] is all words that are near x\n",
    "\n",
    "# Convert set keys into sorted lists for consistent ordering\n",
    "graph = {key: set(graph[key]) for key in graph}\n",
    "# Graph [x] is now a set still, not a list. ???\n",
    "\n",
    "# Calling bron_kerbosch with an empty set, the graph keys (range(1, n+1)), and the whole graph\n",
    "all_cliques = list(bron_kerbosch(set(), set(graph.keys()), set(), graph))\n",
    "\n",
    "# sort and clip all len-1 cliques\n",
    "all_cliques = list(sorted([clique for clique in all_cliques if len(clique) > 1], key = lambda x: -len(x)))\n",
    "\n",
    "print(f'Cliques Found: {len(all_cliques)}; Longest Clique: {len(max(all_cliques, key = len))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c44b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for clique in all_cliques:\n",
    "#     print(set(vectorizer.to_str(idx-1) for idx in clique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8f9f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a file\n",
    "\n",
    "with open(f'discoveries/cliques/{filepath}.txt', 'w') as f:\n",
    "\n",
    "    cliques_string = '\\n'.join([str(set(vectorizer.to_str(idx-1) for idx in clique)) for clique in all_cliques])\n",
    "\n",
    "    cliques_string = f'''Corpus Removal Threshold: {corpus_removal_threshold}\\n\n",
    "Vectorizer Removal Threshold: {vectorizer_removal_threshold}\\n\n",
    "Grouping Similarity: {grouping_similarity}\\n\n",
    "                         \\n''' + cliques_string\n",
    "    \n",
    "    f.write(cliques_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70d1e5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3', '7', '5', '0'}\n"
     ]
    }
   ],
   "source": [
    "search_word = '0'\n",
    "\n",
    "if search_word not in corpus.vocab:\n",
    "    raise Exception(\"Word not in vocabulary\")\n",
    "\n",
    "word_index = vectorizer.to_int(search_word) + 1\n",
    "found = False\n",
    "\n",
    "for clique in all_cliques:\n",
    "    if word_index in clique:\n",
    "        found = True\n",
    "        print(set(vectorizer.to_str(idx-1) for idx in clique))\n",
    "\n",
    "if not found:\n",
    "    print('None found')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

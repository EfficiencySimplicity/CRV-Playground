{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0483b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.Utils import *\n",
    "from classes.CRV import *\n",
    "from classes.Corpus import *\n",
    "from classes.Vectorizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3433633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fda8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_removal_threshold     = 1\n",
    "vectorizer_removal_threshold = 2\n",
    "grouping_similarity          = .6\n",
    "filepath = 'recipes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea7d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collected:\n",
      "    - 12981 unique words found.\n",
      "    - most common words: ['.', 'the', 'i', 'and', '<END>']\n",
      "    - least common words: ['yummy', 'zen', 'ziploc', 'µ', 'ë']\n",
      "\n",
      "\n",
      "Corpus loaded:\n",
      "    - 63969 sentences.\n",
      "    - longest sentence: \n",
      "\n",
      "<START> heads - up : this is a long review and includes suggestions for improvements that i personally would make as well as improvements or modifications that i feel are necessary to avoid having an annoying costume . overall this is a pretty great costume and really only needs a couple of modifications ( tack sew the collar so it isn ' t floppy , make padded arm bands so the sleeves actually poof out , and use a different petticoat ) . read on for a lot more detail . ( and check back for an updated review including before and after pics once i have made the modifications i feel are necessary ) < br / > < br / > as an added note for my kid friendly disney <UNK> : the provided hoop skirt is very much not kid friendly . if you are the type to sit on the floor and hug kids and let them sit with you , the hoop skirt will do nothing but cause problems and stand a chance at damaging your costume . i ' m actually not sure why a simple fluffy petticoat wesson ' t provided , rather than a bulky hoop skirt . skip the hoop skirt and buy a soft petticoat ( or skip the underskirt all together if that ' s your style ) . < br / > < br / > i am a competitive cosplayer , but have resolved to purchase cosplays to wear if i don ' t intend on competing in them , rather than spend time and money ( and stress ) making them myself . this is the first cosplay i have ever purchased online and i have to say that i am very pleasantly surprised ! of course , the biggest issue was the skirt needing to be ironed out . because of the material type and the amount of material , it took me a while , but it was a near instant improvement on the look of the cosplay overall , so be sure to iron that skirt out with your iron set no hotter than the \" silk \" setting ! < br / > < br / > i ordered a xl when i am normally a medium / large ( in stores that run small on sizes ) and the costume fit pretty comfortably . it is a little loose for my tastes and i am intending on losing weight , but i can easily take it in when the time comes . if you are about my size and you prefer comfort over form , i definitely suggest you stick with the xl . it is just my personal preference to look like i am about to compete in a pro contest . if you ' re more like me , then i ' d go with the l . i just don ' t want to bother with the return and re - send shipping process over something that anyone other than myself is unlikely to notice . < br / > < br / > the costume itself is surprisingly weighty . unlike costumes that you buy during halloween , this costume feels like it can stand up to some serious wearing . halloween costumes feel like i am wearing tissue paper and feel like they ' ll fall apart at the smallest hint of moisture . the velvet like material is pretty good quality throughout . the satin like skirt is a little bit difficult as it is somewhat sheer , but this issue can be fixed with a white or yellow underskirt or a better quality petticoat . i am 5 ' 3 \" and about 1 4 0 lbs like the headline says . this is important information because the skirt just kissed the ground while i was walking around my house wearing the dress . if you are on the shorter side like myself and need to order a l , xl , or xxl then i suggest you either get the skirt hemmed up or wear some shoes with small heels just to avoid letting the skirt touch the ground . even with the provided hoop skirt on , the skirt of the dress was still considerably close to the ground , enough so that i ' d be hiking it up and walking like a maniac if i was outside or near anything that may wet or stain the material . < br / > < br / > the collar is a bit floppy , but this can be easily fixed by just sewing tacks in on the bottom corners . the same can be said for the sleeves as they are 1 0 0 % flop and no poof at all . i will need to fix this by making my own inserts . i will update my review later with before and after pictures once i have done this . < br / > < br / > i do have complaints about the bow headband and the petticoat / hoop skirt . the bow is a bit large for my taste . it looks comical and childish , which is not the kind of look i ' d like personally ( it simply disney ' t suit my face shape . if you have a rounder face shape , then it should look just fine on you : ) i just have harder lines and a defined jaw is all ) . i will need to make my own headband , but that is not a big deal . i ' ll see if i can just modify the headband that came with the dress without <UNK> it , but i have concerns that the material won ' t cooperate easily . at the very least , the bow is movable on the headband ! so if you prefer to wear the bow off center or want to use it for other cosplays that may need the bow off center , you can still comfortably wear the headband correctly and simply scoot the bow over to where you need it to be . < br / > < br / > as for the petticoat , it is extremely cheap compared to the quality of the costume . i am actually pretty disappointed in that aspect . the ribbons that are used to tie it off around your waist are not nearly long enough for me to get a secure knot tied in . in order to have a secure knot , i had to pull it uncomfortably tight which made the already difficult task of sitting down nearly impossible due to the discomfort . to add to it , the netting material used on the outside of the hoop skirt that is supposed to help smooth the skirt of the dress out over the form is extremely stiff and defeats it ' s own purpose by being extremely visible underneath the skirt of the dress . it also is not long enough to create that cute bell shape like what is pictured in the listing ( the skirt bells out until the last 8 or so inches , then it ' s like a sheer drop off straight down because there is no longer a petticoat to support it . i even <UNK> the petticoat down so that it was as low on my hips as it could go and i still had that straight drop off with the skirt due to the petticoat not being long enough ) . i have a feeling that this petticoat is a 1 size deal as other reviews that i read for this costume in a smaller size said that the skirt of the dress fit too tightly on the petticoat . aside from the short length , my skirt fit perfectly around this petticoat . this seems like a seller issue that may need to be addressed as petticoats and hoop skirts really iron ' t an appropriate item to make a \" one size fits all \" deal for the exact problems named in my review and in reviews left by others who purchased a smaller size . i will either need to modify this petticoat heavily , purchase a different petticoat , make my own , or go without it all together . < br / > < br / > i do wish the cape was separate from the costume as it will make dealing with the heat somewhat difficult . i also would have preferred a larger cape personally to go with the look in the movie . this is something i may or may not fix in time for an upcoming con , but i will be fixing in the long run . the cape seems to just be sewn on top of the bodice part of the dress , so it will hopefully be as simple as seam ripping the existing cape off and making my own , detachable , larger cape out of a couple of yards of similar material . < br / > < br / > if you want the dress to fit snug like in the picture , then you will need to pin it in the back . the velvet like material is somewhat stretchy , so do be aware of that fact . the cape at least offers a way to hide those pins and , with the zipper being on the side instead of the back , it makes it easy for you to get out of the costume quickly regardless of the pins ( so for those of you who may suffer from anxiety or panic attacks and sometimes need to get out of a costume right now , i can assure you that this cosplay will suit your needs even if you want to pin it up in the back to make it more form fitting . just make sure you do not accidentally pin it to any shape - wear or undershirts you may be wearing underneath ) . < br / > < br / > all in all , i do want to leave 4 / 5 stars because at least the parts that i do have a problem with are minor , considering , and not complicated . it ' s easy to make padded arm bands for bf sleeves , easy to do thread tacks to make something hold its shape , and easy enough to buy a petticoat and make a new headband . had the dress itself had any other issues aside from the not bf sleeves and floppy collar , i ' d have to lower my rating . as a ( very ) competitive cosplayer , i am actually very proud and comfortable to wear this costume . <END>\n",
      ".    \n",
      "    - shortest sentence: \n",
      "\n",
      "<START> <END>\n",
      "Vectorizer created:\n",
      "    - 12981 unique words;\n",
      "    - 10461 CRV words\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(\n",
    "    filepath          = f'corpora/{filepath}',\n",
    "    spell_correct     = 'corpora/spelling_dictionary',\n",
    "    lemmatize         = False,\n",
    "    removal_threshold = corpus_removal_threshold)\n",
    "\n",
    "vectorizer = corpus.create_vectorizer(removal_threshold = vectorizer_removal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0c5d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twentieth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m differences = np.zeros((vectorizer.vsize, vectorizer.vsize,))\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(vectorizer.vsize):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     word_diffs = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mv,bv->bv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     word_diffs = keras.ops.sqrt(word_diffs)\n\u001b[32m      6\u001b[39m     word_diffs = keras.ops.sum(word_diffs, axis = -\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/CRV-Playground/.venv/lib/python3.13/site-packages/keras/src/ops/numpy.py:2855\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(subscripts, *operands)\u001b[39m\n\u001b[32m   2853\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(operands):\n\u001b[32m   2854\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Einsum(subscripts).symbolic_call(*operands)\n\u001b[32m-> \u001b[39m\u001b[32m2855\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubscripts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/CRV-Playground/.venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/numpy.py:443\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(subscripts, *operands, **kwargs)\u001b[39m\n\u001b[32m    439\u001b[39m         compute_dtype = config.floatx()\n\u001b[32m    440\u001b[39m     operands = tree.map_structure(\n\u001b[32m    441\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: tf.cast(x, compute_dtype), operands\n\u001b[32m    442\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     result = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubscripts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tf.cast(result, result_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/CRV-Playground/.venv/lib/python3.13/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/CRV-Playground/.venv/lib/python3.13/site-packages/tensorflow/python/util/dispatch.py:1264\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1266\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1267\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1268\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/CRV-Playground/.venv/lib/python3.13/site-packages/tensorflow/python/ops/special_math_ops.py:763\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(equation, *inputs, **kwargs)\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m'\u001b[39m\u001b[33meinsum\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlinalg.einsum\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    619\u001b[39m \u001b[38;5;129m@dispatch\u001b[39m.add_dispatch_support\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meinsum\u001b[39m(equation, *inputs, **kwargs):\n\u001b[32m    621\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Tensor contraction over specified indices and outer product.\u001b[39;00m\n\u001b[32m    622\u001b[39m \n\u001b[32m    623\u001b[39m \u001b[33;03m  Einsum allows defining Tensors by defining their element-wise computation.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    761\u001b[39m \u001b[33;03m      - number of inputs or their shapes are inconsistent with `equation`.\u001b[39;00m\n\u001b[32m    762\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_einsum_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/CRV-Playground/.venv/lib/python3.13/site-packages/tensorflow/python/ops/special_math_ops.py:1200\u001b[39m, in \u001b[36m_einsum_v2\u001b[39m\u001b[34m(equation, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1198\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m ellipsis_label:\n\u001b[32m   1199\u001b[39m     resolved_equation = resolved_equation.replace(ellipsis_label, \u001b[33m'\u001b[39m\u001b[33m...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1200\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_linalg_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolved_equation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[38;5;66;03m# Send fully specified shapes to opt_einsum, since it cannot handle unknown\u001b[39;00m\n\u001b[32m   1203\u001b[39m \u001b[38;5;66;03m# dimensions. For unknown dimensions, we guess that the dimension equals 1.\u001b[39;00m\n\u001b[32m   1204\u001b[39m \u001b[38;5;66;03m# Instead of creating Tensors or NumPy arrays with the specified shape,\u001b[39;00m\n\u001b[32m   1205\u001b[39m \u001b[38;5;66;03m# create a dummy `shaped` object with a `shape` property.\u001b[39;00m\n\u001b[32m   1206\u001b[39m shaped = collections.namedtuple(\u001b[33m'\u001b[39m\u001b[33mshaped\u001b[39m\u001b[33m'\u001b[39m, [\u001b[33m'\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/CRV-Playground/.venv/lib/python3.13/site-packages/tensorflow/python/ops/gen_linalg_ops.py:1115\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(inputs, equation, name)\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m   1114\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1115\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEinsum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mequation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mequation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   1118\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# get matrix of similarities between all words\n",
    "\n",
    "twentieth = vectorizer.vsize // 20\n",
    "differences = np.zeros((vectorizer.vsize, vectorizer.vsize,))\n",
    "\n",
    "for i in range(vectorizer.vsize):\n",
    "    word_diffs = keras.ops.einsum('v,bv->bv', vectorizer.matrix[i], vectorizer.matrix)\n",
    "    word_diffs = keras.ops.sqrt(word_diffs)\n",
    "    word_diffs = keras.ops.sum(word_diffs, axis = -1)\n",
    "    word_diffs *= word_diffs\n",
    "    differences[i] = word_diffs.numpy()\n",
    "    \n",
    "    if (i % twentieth == 0):\n",
    "        print('twentieth')\n",
    "\n",
    "differences *= (1 - np.eye(differences.shape[0], differences.shape[1]))\n",
    "similar_words = np.asarray(differences >= grouping_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6726b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21160\n"
     ]
    }
   ],
   "source": [
    "coords = np.array(similar_words.nonzero())\n",
    "print(len(coords[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837a146a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Convert set keys into sorted lists for consistent ordering\u001b[39;00m\n\u001b[32m     27\u001b[39m graph = {key: \u001b[38;5;28mset\u001b[39m(graph[key]) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m graph}\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m all_cliques = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbron_kerbosch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m all_cliques = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m([clique \u001b[38;5;28;01mfor\u001b[39;00m clique \u001b[38;5;129;01min\u001b[39;00m all_cliques \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(clique) > \u001b[32m1\u001b[39m], key = \u001b[38;5;28;01mlambda\u001b[39;00m x: -\u001b[38;5;28mlen\u001b[39m(x)))\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCliques Found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_cliques)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m; Longest Clique: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mmax\u001b[39m(all_cliques,\u001b[38;5;250m \u001b[39mkey\u001b[38;5;250m \u001b[39m=\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mbron_kerbosch\u001b[39m\u001b[34m(R, P, X, graph)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m P:\n\u001b[32m      7\u001b[39m     v = P.pop()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m bron_kerbosch(\n\u001b[32m      9\u001b[39m         R.union({v}),\n\u001b[32m     10\u001b[39m         P.intersection(graph[v]),\n\u001b[32m     11\u001b[39m         X.intersection(graph[v]),\n\u001b[32m     12\u001b[39m         graph\n\u001b[32m     13\u001b[39m     )\n\u001b[32m     14\u001b[39m     X.add(v)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mbron_kerbosch\u001b[39m\u001b[34m(R, P, X, graph)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m P:\n\u001b[32m      7\u001b[39m     v = P.pop()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m bron_kerbosch(\n\u001b[32m      9\u001b[39m         R.union({v}),\n\u001b[32m     10\u001b[39m         P.intersection(graph[v]),\n\u001b[32m     11\u001b[39m         X.intersection(graph[v]),\n\u001b[32m     12\u001b[39m         graph\n\u001b[32m     13\u001b[39m     )\n\u001b[32m     14\u001b[39m     X.add(v)\n",
      "    \u001b[31m[... skipping similar frames: bron_kerbosch at line 8 (60 times)]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mbron_kerbosch\u001b[39m\u001b[34m(R, P, X, graph)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m P:\n\u001b[32m      7\u001b[39m     v = P.pop()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m bron_kerbosch(\n\u001b[32m      9\u001b[39m         R.union({v}),\n\u001b[32m     10\u001b[39m         P.intersection(graph[v]),\n\u001b[32m     11\u001b[39m         X.intersection(graph[v]),\n\u001b[32m     12\u001b[39m         graph\n\u001b[32m     13\u001b[39m     )\n\u001b[32m     14\u001b[39m     X.add(v)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mbron_kerbosch\u001b[39m\u001b[34m(R, P, X, graph)\u001b[39m\n\u001b[32m      7\u001b[39m v = P.pop()\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m bron_kerbosch(\n\u001b[32m      9\u001b[39m     R.union({v}),\n\u001b[32m     10\u001b[39m     P.intersection(graph[v]),\n\u001b[32m     11\u001b[39m     X.intersection(graph[v]),\n\u001b[32m     12\u001b[39m     graph\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/dsa/maximal-clique-problem-recursive-solution/\n",
    "\n",
    "def bron_kerbosch(R, P, X, graph):\n",
    "    if not P and not X:\n",
    "        yield R\n",
    "    while P:\n",
    "        v = P.pop()\n",
    "        yield from bron_kerbosch(\n",
    "            R.union({v}),\n",
    "            P.intersection(graph[v]),\n",
    "            X.intersection(graph[v]),\n",
    "            graph\n",
    "        )\n",
    "        X.add(v)\n",
    "\n",
    "\n",
    "edges = [(int(coords[0,i])+1, int(coords[1,i])+1) for i in range(coords.shape[1])]\n",
    "n = len(corpus.vocab)  # Number of nodes\n",
    "\n",
    "# Create an adjacency list from the edges\n",
    "graph = {i: set() for i in range(1, n + 1)}\n",
    "for u, v in edges:\n",
    "    graph[u].add(v)\n",
    "    graph[v].add(u)\n",
    "# Graph [x] is all words that are near x\n",
    "\n",
    "# Convert set keys into sorted lists for consistent ordering\n",
    "graph = {key: set(graph[key]) for key in graph}\n",
    "# Graph [x] is now a set still, not a list. ???\n",
    "\n",
    "# Calling bron_kerbosch with an empty set, the graph keys (range(1, n+1)), and the whole graph\n",
    "all_cliques = list(bron_kerbosch(set(), set(graph.keys()), set(), graph))\n",
    "\n",
    "# sort and clip all len-1 cliques\n",
    "all_cliques = list(sorted([clique for clique in all_cliques if len(clique) > 1], key = lambda x: -len(x)))\n",
    "\n",
    "print(f'Cliques Found: {len(all_cliques)}; Longest Clique: {len(max(all_cliques, key = len))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for clique in all_cliques:\n",
    "#     print(set(vectorizer.to_str(idx-1) for idx in clique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a file\n",
    "\n",
    "with open(f'discoveries/cliques/{filepath}.txt', 'w') as f:\n",
    "\n",
    "    cliques_string = '\\n'.join([str(set(vectorizer.to_str(idx-1) for idx in clique)) for clique in all_cliques])\n",
    "\n",
    "    cliques_string = f'''Corpus Removal Threshold: {corpus_removal_threshold}\\n\n",
    "Vectorizer Removal Threshold: {vectorizer_removal_threshold}\\n\n",
    "Grouping Similarity: {grouping_similarity}\\n\n",
    "                         \\n''' + cliques_string\n",
    "    \n",
    "    f.write(cliques_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1e5f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Word not in vocabulary",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# grandma fahrenheit blend\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m search_word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m corpus.vocab:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mWord not in vocabulary\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m word_index = vectorizer.to_int(search_word) + \u001b[32m1\u001b[39m\n\u001b[32m      9\u001b[39m found = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mException\u001b[39m: Word not in vocabulary"
     ]
    }
   ],
   "source": [
    "search_word = '0'\n",
    "\n",
    "if search_word not in corpus.vocab:\n",
    "    raise Exception(\"Word not in vocabulary\")\n",
    "\n",
    "word_index = vectorizer.to_int(search_word) + 1\n",
    "found = False\n",
    "\n",
    "for clique in all_cliques:\n",
    "    if word_index in clique:\n",
    "        found = True\n",
    "        print(set(vectorizer.to_str(idx-1) for idx in clique))\n",
    "\n",
    "if not found:\n",
    "    print('None found')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
